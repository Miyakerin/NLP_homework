{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9290bd9b-e4d1-4c77-92c9-b853898992bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9290bd9b-e4d1-4c77-92c9-b853898992bc",
    "outputId": "4d20be58-d568-4d31-b33b-8a4b85e731ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import zipfile\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0f290f-62a2-431d-9952-7ffc9450b0b3",
   "metadata": {
    "id": "8b0f290f-62a2-431d-9952-7ffc9450b0b3",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19fcab-6fa5-4086-901c-224f33f2e3fc",
   "metadata": {
    "id": "4f19fcab-6fa5-4086-901c-224f33f2e3fc"
   },
   "outputs": [],
   "source": [
    "data = urllib.request.urlopen('https://s3.amazonaws.com/text-datasets/nietzsche.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90003fc2-206a-49ff-992d-d7f05ba4a152",
   "metadata": {
    "id": "90003fc2-206a-49ff-992d-d7f05ba4a152"
   },
   "outputs": [],
   "source": [
    "raw_text = \"\"\n",
    "for i in data:\n",
    "    raw_text += i.decode('utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb821a9-b991-49f0-8a80-ef7335e94007",
   "metadata": {
    "id": "2bb821a9-b991-49f0-8a80-ef7335e94007",
    "outputId": "7b599b21-c6e6-4026-d9a7-4e1ea4d39873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus len = 600893\n",
      "sentence count = 2864\n",
      "chars used = 57\n"
     ]
    }
   ],
   "source": [
    "print(f'corpus len = {len(raw_text)}\\nsentence count = {len(nltk.sent_tokenize(raw_text))}\\nchars used = {len(set(raw_text))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e57dff-89ed-497f-b619-27f36438366a",
   "metadata": {
    "id": "d0e57dff-89ed-497f-b619-27f36438366a",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80fda8d-fcdc-4887-9a83-b97a7bd1e075",
   "metadata": {
    "id": "d80fda8d-fcdc-4887-9a83-b97a7bd1e075",
    "outputId": "326f737c-15de-44e6-c20a-d4ea0471e1c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300427\n"
     ]
    }
   ],
   "source": [
    "seq_len = 40\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "dataX = []\n",
    "dataY = []\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(char_to_int)\n",
    "for i in range(0, n_chars - seq_len, 2):\n",
    "    seq_in = raw_text[i: i + seq_len]\n",
    "    seq_out = raw_text[i + seq_len]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append([char_to_int[seq_out]])\n",
    "print(len(dataX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665780c7-20f8-4360-ba72-f37273eda2a4",
   "metadata": {
    "id": "665780c7-20f8-4360-ba72-f37273eda2a4",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b51973-1bb2-4f9c-981c-e123090de277",
   "metadata": {
    "id": "21b51973-1bb2-4f9c-981c-e123090de277",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Вспомогательные ф-ции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c05e09-bf4e-4ce4-b002-f8637182bbbc",
   "metadata": {
    "id": "f8c05e09-bf4e-4ce4-b002-f8637182bbbc"
   },
   "outputs": [],
   "source": [
    "# создание датасета\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.word_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        data = urllib.request.urlopen('https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "        raw_text = \"\"\n",
    "        for i in data:\n",
    "            raw_text += i.decode('utf-8').lower()\n",
    "        return list(nltk.word_tokenize(raw_text))\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_indexes) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(self.word_indexes[index:index+self.seq_len]),\n",
    "                torch.tensor(self.word_indexes[index+1:index+self.seq_len+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a865d9f-55d9-425f-bc39-c77874dc566f",
   "metadata": {
    "id": "6a865d9f-55d9-425f-bc39-c77874dc566f"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 256\n",
    "        self.num_layers = 3\n",
    "        self.seq_len = dataset.seq_len\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = self.embedding_dim,\n",
    "            hidden_size = self.lstm_size,\n",
    "            num_layers = self.num_layers,\n",
    "            dropout = 0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, state = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def init_state(self):\n",
    "        return (torch.zeros(self.num_layers, self.seq_len, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, self.seq_len, self.lstm_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c892a7-97a6-42db-9ebf-53b221313b1a",
   "metadata": {
    "id": "81c892a7-97a6-42db-9ebf-53b221313b1a"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = []\n",
    "    for (local_batch, local_label) in dataloader:\n",
    "        (local_batch, local_label) = (local_batch.to(device), local_label.to(device))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model.forward(local_batch)\n",
    "        curr_loss = criterion.forward(y_pred.transpose(1, 2), local_label)\n",
    "\n",
    "        curr_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(curr_loss.item())\n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90521a6-6e02-4776-8330-5547694b5377",
   "metadata": {
    "id": "b90521a6-6e02-4776-8330-5547694b5377"
   },
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, device, next_words=20):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i::]]]).to(device)\n",
    "        y_pred = model.forward(x)\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().to('cpu').numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedc2756-b84e-4566-a138-03aaa49b908c",
   "metadata": {
    "id": "fedc2756-b84e-4566-a138-03aaa49b908c",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7b659-1a4a-4106-afe6-49abb953dd59",
   "metadata": {
    "id": "2fd7b659-1a4a-4106-afe6-49abb953dd59"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 300\n",
    "num_epochs = 30\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache() if device == 'cuda' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a6939-c157-4545-95b2-7cff4701eeae",
   "metadata": {
    "id": "f43a6939-c157-4545-95b2-7cff4701eeae"
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb1f16c-a4fb-4332-89bf-fb20932e4dfe",
   "metadata": {
    "id": "6bb1f16c-a4fb-4332-89bf-fb20932e4dfe"
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb40c6-3db1-4eed-ba0e-002a02beead1",
   "metadata": {
    "id": "a5cb40c6-3db1-4eed-ba0e-002a02beead1"
   },
   "outputs": [],
   "source": [
    "model = Model(dataset).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64537ee6-1813-4f54-b6cb-28f8a40f3dc7",
   "metadata": {
    "id": "64537ee6-1813-4f54-b6cb-28f8a40f3dc7",
    "outputId": "c34def44-b749-480d-ffd5-d3d44524c38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кол-во параметров в модели = 4701444\n"
     ]
    }
   ],
   "source": [
    "print(f'кол-во параметров в модели = {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb00e2-b580-41d0-bc65-4ba2c812f5be",
   "metadata": {
    "id": "7edb00e2-b580-41d0-bc65-4ba2c812f5be",
    "outputId": "ab15c322-e44a-4558-98b0-96f33a569931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda? - True\n"
     ]
    }
   ],
   "source": [
    "print('is cuda? -',next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa740a-33d9-4aa2-b957-2606c80583fc",
   "metadata": {
    "id": "47aa740a-33d9-4aa2-b957-2606c80583fc"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295fd68-9e71-4f50-bf43-2bedfcd1afc3",
   "metadata": {
    "id": "0295fd68-9e71-4f50-bf43-2bedfcd1afc3",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## train & pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49703bec-03a2-4a61-82e7-f7fed1e49261",
   "metadata": {
    "id": "49703bec-03a2-4a61-82e7-f7fed1e49261",
    "outputId": "208c7fb2-9d53-412b-c8c8-cce41e007836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochN=1, pred text = the truth is in by maturity satisfaction begins , more too himself would , estimations free in , an and good , truth\n",
      "epochN=2, pred text = the truth is suffering to , that almost , according are breath already the =the so , necessary . my no of reproach\n",
      "epochN=3, pred text = the truth is the whole ( himself that is was who without nothing , c'est-a-dire to such farcical the history of those ,\n",
      "epochN=4, pred text = the truth is they its first pity -- if no utmost envy as in the purpose , now in matter , in the\n",
      "epochN=5, pred text = the truth is always things with the invented ramification by moral acts in rank -- which packed instantly , '' '' '' are\n",
      "epochN=6, pred text = the truth is thus eloquence fast to satisfactory disgust ) . as `` the else over learn to separates the objective individual ,\n",
      "epochN=7, pred text = the truth is rarely blessed as a thing ? and he did one who , or already stare and self fascinatingly towards effaced\n",
      "epochN=8, pred text = the truth is possible to understand with an delight as any our bliss of the `` occasions '' attains the gold and alleviation\n",
      "epochN=9, pred text = the truth is only a step to itself . `` everything is requires , thereby , destroying to rebaptize themselves into the subject\n",
      "epochN=10, pred text = the truth is evoke to play the other number in the farthest abstract : '' all the will also , clay , 16\n",
      "epochN=11, pred text = the truth is that , however , as an inclination in the man of christianity , a terrible interfered contempt . these natural\n",
      "epochN=12, pred text = the truth is prepared that clear is to present-day purpose.= as certainly on the intellect becoming believed of regard to an ancient interest\n",
      "epochN=13, pred text = the truth is , according to athens and are `` gay longer '' ? and more then required no real circle of his\n",
      "epochN=14, pred text = the truth is unscholarly thereby . sache must , a huntsman does nothing this highly mothers on the problems of contradicts the word\n",
      "epochN=15, pred text = the truth is so arranged nothing there of artistic . when we wait among suspicion and roaming of it and at present that\n",
      "epochN=16, pred text = the truth is therefore being the master of those experiences ! apparently we write -- the world says , splendidly approach to withdrawing\n",
      "epochN=17, pred text = the truth is not suspicious in the case of whom all the heart of their whole , is lost with all another ,\n",
      "epochN=18, pred text = the truth is stupid only further ago : a side of badness . ] he knew himself ? with a `` distance ''\n",
      "epochN=19, pred text = the truth is developed ? a promise as the perfume of shame pangs -- which have been the greatest stages of his situation\n",
      "epochN=20, pred text = the truth is found in the sense of self-preservation and travel ; only against the disease fear of a people , without a\n",
      "epochN=21, pred text = the truth is known up to the conviction and the genuine , involuntary , obstructive , or imperious and regrettably , to call\n",
      "epochN=22, pred text = the truth is to be sure , be determined that is , and on the present belief the former for the standpoint of\n",
      "epochN=23, pred text = the truth is the standard of feeling of thought other ( more amounts to the higher light of dealing for the canon in\n",
      "epochN=24, pred text = the truth is pinned that why stood to the jews ; we state , things therefore , who knows ; counter to pascal-like\n",
      "epochN=25, pred text = the truth is seldom emboldened to be space , the sunshine of all truth . youth is evidence to them ; it is\n",
      "epochN=26, pred text = the truth is its typical artists he changes and cool as his guilt ' that egoism , under the last resort , now\n",
      "epochN=27, pred text = the truth is good even as coming -- down too effectively and discoverer , consequently deal as it were squandered by his legs\n",
      "epochN=28, pred text = the truth is at any rate , except it is once who perhaps real teachers of wishing to afford an end , but\n",
      "epochN=29, pred text = the truth is possible , therefore , it comprehends , into the bible have disclosed apart and despairing , represent as the use\n",
      "epochN=30, pred text = the truth is possible ; most not to think that anybody formerly now a bond of theorising 's black spectacles : '' --\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "text = 'the truth is'\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = train_one_epoch(model, data_loader, criterion, optimizer, device)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(f'epochN={epoch+1}, pred text = {predict(dataset, model, text, device)}')\n",
    "torch.cuda.empty_cache() if device == 'cuda' else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52380b4-c667-4424-96d9-da0baf2b96a9",
   "metadata": {
    "id": "a52380b4-c667-4424-96d9-da0baf2b96a9"
   },
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kWUCvOdX19y9",
   "metadata": {
    "id": "kWUCvOdX19y9"
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "upYmqQIKZs0P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "upYmqQIKZs0P",
    "outputId": "bc460b27-fbc3-495a-cb98-388375cc7ead"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-4485d88d-b8ec-4364-8ee2-e7e8c606f5d4\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-4485d88d-b8ec-4364-8ee2-e7e8c606f5d4\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"voltjunkie\",\"key\":\"b8039b43db8bce188ad021ee693b99f0\"}'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "XpaWW2nVZzvL",
   "metadata": {
    "id": "XpaWW2nVZzvL"
   },
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09vW2socZ1H_",
   "metadata": {
    "id": "09vW2socZ1H_"
   },
   "outputs": [],
   "source": [
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mONL_A8eZ3QI",
   "metadata": {
    "id": "mONL_A8eZ3QI"
   },
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "GigJkEwW23o9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GigJkEwW23o9",
    "outputId": "3dbf550a-b014-4b4b-d497-dd84bba7a358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading wikibooks-dataset.zip to /content\n",
      "100% 1.82G/1.82G [00:19<00:00, 47.8MB/s]\n",
      "100% 1.82G/1.82G [00:19<00:00, 99.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d dhruvildave/wikibooks-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aJ0FJS413pp_",
   "metadata": {
    "id": "aJ0FJS413pp_"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(r'C:\\Users\\user\\Desktop\\dz\\nlp\\data\\wikibooks-dataset.zip', 'r') as zip:\n",
    "  zip.extractall(r'C:\\Users\\user\\Desktop\\dz\\nlp\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ne5fKwEh0lr-",
   "metadata": {
    "id": "ne5fKwEh0lr-"
   },
   "source": [
    "## Вспомогательные ф-ции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "uKwtkACn0lsB",
   "metadata": {
    "id": "uKwtkACn0lsB"
   },
   "outputs": [],
   "source": [
    "# создание датасета\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        self.words = self.load_df()\n",
    "\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.word_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "\n",
    "    def load_df(self):\n",
    "        conn = sqlite3.connect(r'C:\\Users\\user\\Desktop\\dz\\nlp\\data\\wikibooks.sqlite')\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT * FROM ru;\")\n",
    "        data = cur.fetchall()\n",
    "\n",
    "        cur.execute(\"PRAGMA table_info(ru);\")\n",
    "        column_names = cur.fetchall()\n",
    "        column_names = [column[1] for column in column_names]\n",
    "\n",
    "        df = pd.DataFrame(data, columns=column_names)\n",
    "        df['title'] = df['title'].str.lower()\n",
    "        sequences = list(df['title'])\n",
    "        words = [[word for word in list(nltk.word_tokenize(seq))] for seq in sequences]\n",
    "        words = list(chain.from_iterable(words))\n",
    "        return words\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_indexes) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(self.word_indexes[index:index+self.seq_len]),\n",
    "                torch.tensor(self.word_indexes[index+1:index+self.seq_len+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "SgnbS7Hs0lsC",
   "metadata": {
    "id": "SgnbS7Hs0lsC"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 256\n",
    "        self.num_layers = 3\n",
    "        self.seq_len = dataset.seq_len\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = self.embedding_dim,\n",
    "            hidden_size = self.lstm_size,\n",
    "            num_layers = self.num_layers,\n",
    "            dropout = 0.2,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, state = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "BIjPQpeb0lsC",
   "metadata": {
    "id": "BIjPQpeb0lsC"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = []\n",
    "    for (local_batch, local_label) in dataloader:\n",
    "        (local_batch, local_label) = (local_batch.to(device), local_label.to(device))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model.forward(local_batch)\n",
    "        curr_loss = criterion.forward(y_pred.transpose(1, 2), local_label)\n",
    "\n",
    "        curr_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(curr_loss.item())\n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c9c2d1-be66-484a-9a9f-d59a338d89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, device, next_words=14):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i::]]]).to(device)\n",
    "        y_pred = model.forward(x)\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().to('cpu').numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aNQwmZyF0lsE",
   "metadata": {
    "id": "aNQwmZyF0lsE"
   },
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "CcxRzgok0lsE",
   "metadata": {
    "id": "CcxRzgok0lsE"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 40\n",
    "num_epochs = 30\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache() if device == 'cuda' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "jYwA3nL90lsF",
   "metadata": {
    "id": "jYwA3nL90lsF"
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "JsECN9k40lsF",
   "metadata": {
    "id": "JsECN9k40lsF"
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Dvdmr6U80lsG",
   "metadata": {
    "id": "Dvdmr6U80lsG"
   },
   "outputs": [],
   "source": [
    "model = Model(dataset).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lPnFCTzh0lsG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPnFCTzh0lsG",
    "outputId": "2cb3ebe6-4d58-4703-c70f-afb3a2a4a191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кол-во параметров в модели = 5013294\n"
     ]
    }
   ],
   "source": [
    "print(f'кол-во параметров в модели = {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1wId3VFm0lsI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wId3VFm0lsI",
    "outputId": "e0f3dd72-6404-4cf2-b2ee-ca6463c1e760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda? - True\n"
     ]
    }
   ],
   "source": [
    "print('is cuda? -',next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "VLSWW4rO0lsJ",
   "metadata": {
    "id": "VLSWW4rO0lsJ"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0yJ7lOvbniy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0yJ7lOvbniy",
    "outputId": "3569e502-2227-40ee-d443-96dde08605f0"
   },
   "outputs": [],
   "source": [
    "pred = \" \".join([dataset.index_to_word.get(w, \"\") for w in dataset[0][0].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74104138-699d-4587-8e3b-4a60048c58eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'викиучебник : техника и технология средств массовой информации/интернет/техника викиучебник : аон/пилотское свидетельство викиучебник'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "jt3YkviMan5F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jt3YkviMan5F",
    "outputId": "f7e345a0-28fb-4228-9c98-625f6d7f6d5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(11822, 256)\n",
       "  (lstm): LSTM(256, 128, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=128, out_features=11822, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zs9LW5aQ0lsJ",
   "metadata": {
    "id": "zs9LW5aQ0lsJ"
   },
   "source": [
    "## train & pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "817b533f-12c4-4bf6-8b71-bf174867cac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochN=1, pred text = викиучебник : техника и справочник/kodak 1998 викиучебник : коктейли/смородиновая разработок викиучебник : коктейли/колавайцен викиучебник : техника викиучебник :\n",
      "epochN=2, pred text = викиучебник : техника и примерах/управляющие многомерных . рекомендациям викиучебник : аон/пилотское диз викиучебник : интересное 24/стадии экспертиза по\n",
      "epochN=3, pred text = викиучебник : техника и технология средств массовой информации/телевидение/технология викиучебник : коктейли/тайлер регулирование урок на социальные миндалин викиучебник :\n",
      "epochN=4, pred text = викиучебник : техника и технология средств массовой информации/печатная школы/теорема комплекса викиучебник : русско-сербский психология/пролонгированные викиучебник : коктейли/рашин мохито\n",
      "epochN=5, pred text = викиучебник : техника и технология средств массовой информации/радио/история радио викиучебник : коктейли/дейзи викиучебник : интеллектуальное право/примеры рунический 09.12.2016\n",
      "epochN=6, pred text = викиучебник : техника и технология средств массовой информации/послепечатный процесс викиучебник : фоторецептурный справочник/c-41 засвеченной общественных части викиучебник :\n",
      "epochN=7, pred text = викиучебник : техника и технология средств массовой информации/печатная периодика/техника викиучебник : коктейли/обжигающий лу викиучебник : интеллектуальное freshness викиучебник\n",
      "epochN=8, pred text = викиучебник : техника и технология средств массовой информации/радио/история периодика/программное 2007 викиучебник : коктейли/молочный пунш с водкой викиучебник :\n",
      "epochN=9, pred text = викиучебник : техника и технология средств массовой информации/печатная периодика/программное пациента викиучебник : автомобиль/ремонт интернет-представительство реестра документов об образовании\n",
      "epochN=10, pred text = викиучебник : техника и технология средств массовой информации/фотожурналистика/технология викиучебник : gnu octave/короткое урок такое python викиучебник : книга\n",
      "epochN=11, pred text = викиучебник : техника и технология средств массовой информации/машинный перевод викиучебник : коктейли/восточный сад викиучебник : викигид викиучебник :\n",
      "epochN=12, pred text = викиучебник : техника и технология средств массовой информации викиучебник : самоучитель английского программирования/haskell/ввод-вывод викиучебник : учебник по программированию/тонкий\n",
      "epochN=13, pred text = викиучебник : техника и технология средств массовой информации/машинный перевод викиучебник : бюджетирование/семинар 9 викиучебник : коктейли/дайкири со спрайтом\n",
      "epochN=14, pred text = викиучебник : техника и технология средств массовой сленга викиучебник : северная мушка викиучебник : гавайеведение/гавайская геология викиучебник :\n",
      "epochN=15, pred text = викиучебник : техника и технология средств массовой информации/радиожурналистика/программное обеспечение викиучебник : коктейли/бойлермейкер викиучебник : курс лекций защита информации/обобщенная\n",
      "epochN=16, pred text = викиучебник : техника и технология средств массовой информации/печатная периодика/техника викиучебник : latex/форматирование информационных mojito викиучебник : наглядный josm/подробное\n",
      "epochN=17, pred text = викиучебник : техника и технология средств массовой информации/электронные словари викиучебник : основы алгебры/правило переноса слагаемого викиучебник : коктейли/негрони\n",
      "epochN=18, pred text = викиучебник : техника и технология средств массовой информации/фотожурналистика/технология викиучебник : коктейли/бурбон с спрайтом викиучебник : коктейли/американо-оранж викиучебник :\n",
      "epochN=19, pred text = викиучебник : техника и технология средств массовой информации/радио/история радио викиучебник : коктейли/puka punch викиучебник : тесты нмо/оказание скорой\n",
      "epochN=20, pred text = викиучебник : техника и технология средств массовой информации/фотожурналистика/программное обеспечение викиучебник : геометрия для средней школы/теорема пифагора викиучебник :\n",
      "epochN=21, pred text = викиучебник : техника и технология средств массовой информации/послепечатный процесс викиучебник : коктейли/зеленый зверь викиучебник : биология клетки/часть 1.\n",
      "epochN=22, pred text = викиучебник : техника и технология средств массовой информации/телевидение/программное обеспечение викиучебник : коктейли/виски с каса викиучебник : коктейли/белый глинтвейн\n",
      "epochN=23, pred text = викиучебник : техника и технология средств массовой информации/печатный процесс викиучебник : клиническая психология/нарушения мышления при локальных повреждениях головного\n",
      "epochN=24, pred text = викиучебник : техника и технология средств массовой информации/печатный процесс викиучебник : клиническая психология/специфика органических поражений мозга и нейропсихологической\n",
      "epochN=25, pred text = викиучебник : техника и технология средств массовой информации/печатный процесс викиучебник : клиническая психология/психосоматика как область междисциплинарных исследований взаимосвязи\n",
      "epochN=26, pred text = викиучебник : техника и технология средств массовой информации/телевидение/техника викиучебник : коктейли/чистилище викиучебник : коктейли/мандарин шот викиучебник : русско-сербский\n",
      "epochN=27, pred text = викиучебник : техника и технология средств массовой информации/макетирование и верстка викиучебник : коктейли/прыжок лягушки викиучебник : биология клетки/часть\n",
      "epochN=28, pred text = викиучебник : техника и технология средств массовой информации/история телевидения викиучебник : коктейли/эсквайр викиучебник : abap/bc/выгрузка транспортных запросов викиучебник\n",
      "epochN=29, pred text = викиучебник : техника и технология средств массовой информации/фотожурналистика/техника викиучебник : blender 3d ( первый вариант перевода ) /служебное\n",
      "epochN=30, pred text = викиучебник : техника и технология средств массовой информации/телевидение/программное обеспечение викиучебник : suomen kieli käyttöön/rahankäytöopas викиучебник : java/запуск программы\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "text = 'Викиучебник : Техника и'.lower()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = train_one_epoch(model, data_loader, criterion, optimizer, device)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(f'epochN={epoch+1}, pred text = {predict(dataset, model, text, device)}')\n",
    "torch.cuda.empty_cache() if device == 'cuda' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e64b9-8f37-42f6-aebb-17a2fbe98037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
